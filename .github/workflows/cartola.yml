name: Load Cartola Data

on:
  # fixit readd
  # schedule:
  #   # Run daily at 10:00 UTC (during Cartola market hours)
  #   - cron: "0 10 * * *"
  workflow_dispatch:
    inputs:
      environment:
        description: "Environment to deploy to"
        required: true
        type: choice
        options:
          - dev
          - demo
          - prod

env:
  GCP_PROJECT_ID: fantasy-br

jobs:
  load-data:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write

    env:
      BQ_DATASET_ID: fdm${{ inputs.environment }}_fantasy_br

    steps:
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Fetch Cartola API data
        run: |
          curl -sL "https://api.cartolafc.globo.com/atletas/mercado" -o market.json
          echo "Downloaded $(wc -c < market.json) bytes"

      - name: Extract and load players
        run: |
          jq -c '.atletas[]' market.json > players_all.jsonl
          API_COUNT=$(wc -l < players_all.jsonl | tr -d ' ')

          # Check if table exists
          if bq show "${GCP_PROJECT_ID}:${BQ_DATASET_ID}.raw_players" > /dev/null 2>&1; then

            # Table exists, get existing atleta_id + rodada_id combinations
            bq query --use_legacy_sql=false --format=csv --max_rows=100000 \
              "SELECT DISTINCT CONCAT(CAST(atleta_id AS STRING), '_', CAST(rodada_id AS STRING)) as key 
               FROM \`${GCP_PROJECT_ID}.${BQ_DATASET_ID}.raw_players\`" \
              | tail -n +2 > existing_keys.txt
            
            # Filter out existing combinations
            # This is done locally to avoid billing requirement on BigQuery for the filtering step
            jq -c --slurpfile keys <(jq -R -s 'split("\n") | map(select(length > 0))' existing_keys.txt) \
              'select(("\(.atleta_id)_\(.rodada_id)" | IN($keys[0][])) | not)' \
              players_all.jsonl > players_new.jsonl

          # Table does not exist, all players are new
          else
            cp players_all.jsonl players_new.jsonl
          fi

          NEW_COUNT=$(wc -l < players_new.jsonl | tr -d ' ')

          if [ "$NEW_COUNT" -gt 0 ]; then
            bq load --source_format=NEWLINE_DELIMITED_JSON --autodetect \
              --schema_update_option=ALLOW_FIELD_ADDITION \
              "${GCP_PROJECT_ID}:${BQ_DATASET_ID}.raw_players" players_new.jsonl
            echo "API returned ${API_COUNT} players, inserted ${NEW_COUNT} new rows"
          else
            echo "API returned ${API_COUNT} players, no new rows to insert"
          fi

      - name: Extract and load clubs
        run: |
          jq -c '.clubes[]' market.json > clubs.jsonl
          bq load --source_format=NEWLINE_DELIMITED_JSON --autodetect --replace \
            "${GCP_PROJECT_ID}:${BQ_DATASET_ID}.raw_clubs" clubs.jsonl
          echo "Loaded $(wc -l < clubs.jsonl) clubs"

      - name: Extract and load positions
        run: |
          jq -c '.posicoes[]' market.json > positions.jsonl
          bq load --source_format=NEWLINE_DELIMITED_JSON --autodetect --replace \
            "${GCP_PROJECT_ID}:${BQ_DATASET_ID}.raw_positions" positions.jsonl
          echo "Loaded $(wc -l < positions.jsonl) positions"

      - name: Extract and load status
        run: |
          jq -c '.status[]' market.json > status.jsonl
          bq load --source_format=NEWLINE_DELIMITED_JSON --autodetect --replace \
            "${GCP_PROJECT_ID}:${BQ_DATASET_ID}.raw_status" status.jsonl
          echo "Loaded $(wc -l < status.jsonl) status"
